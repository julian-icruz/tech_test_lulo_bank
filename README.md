# Lulo Bank Technical Test ðŸ¦

## ðŸ“š Tabla de Contenido
- [ðŸ” DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
    - [ðŸŽ¯ Objetivos](#objetivos)
    - [ðŸš€ Beneficios](#beneficios)

- [ðŸ—‚ï¸ Estructura del Proyecto](#estructura-del-proyecto)
- [ðŸŽ¨ Patrones Aplicados](#patrones-aplicados)
- [ðŸš€ Despliegue de la AplicaciÃ³n](#despliegue-de-la-aplicaciÃ³n)
- [ðŸ“– Resumen de Endpoints y CÃ³mo Usarlos](#resumen-de-endpoints-y-cÃ³mo-usarlos)
    - [Endpoints de Extract](#endpoints-de-extract)
    - [Endpoints de Transform](#endpoints-de-transform)
    - [Endpoint de Load](#endpoint-de-load)
- [âœ… Ejecutar Tests Unitarios](#ejecutar-tests-unitarios)



## DescripciÃ³n del Proyecto
El proyecto **Lulo Bank Tech Test** es una aplicaciÃ³n que demuestra cÃ³mo construir una soluciÃ³n tÃ©cnica robusta usando Python y FastAPI. Su enfoque principal es implementar procesos ETL (ExtracciÃ³n, TransformaciÃ³n y Carga) y microservicios para resolver desafÃ­os empresariales.

### Objetivos
- **EvaluaciÃ³n TÃ©cnica:** Mostrar buenas prÃ¡cticas (SOLID, patrones de diseÃ±o).
- **IntegraciÃ³n:** Combinar extracciÃ³n de datos (API TVMaze), transformaciÃ³n y carga en bases de datos (Postgres/MySQL).
- **Microservicios:** Construir una arquitectura modular y escalable con FastAPI.
- **Calidad y Testeo:** Asegurar un cÃ³digo mantenible y bien probado.

### Beneficios
- **Mantenibilidad:** CÃ³digo modular y fÃ¡cil de actualizar.
- **Escalabilidad:** Arquitectura preparada para crecer segÃºn las necesidades.
- **Flexibilidad:** Soporte para mÃºltiples formatos y motores de lectura/escritura (CSV, JSON, Parquet, YAML, HTML, PDF) tanto en local como en AWS S3.
Â¿Te parece bien este formato o deseas ajustar algÃºn detalle?

## Estructura del Proyecto

El proyecto estÃ¡ organizado de manera modular para facilitar su mantenimiento y escalabilidad. A continuaciÃ³n, se muestra un resumen de la estructura principal:

- **pyproject.toml** ðŸ“¦
  ConfiguraciÃ³n del proyecto y sus dependencias.

- **docker-compose.yml** ðŸ³
  Define los servicios y contenedores (Postgres, pgAdmin, migraciones y la aplicaciÃ³n).

- **app/** ðŸ’»
  Carpeta principal con el cÃ³digo fuente:
  - **main.py** ðŸš€
    Punto de entrada de la aplicaciÃ³n FastAPI.
  - **setup.py** âš™ï¸
    InicializaciÃ³n y configuraciÃ³n de la aplicaciÃ³n.
  - **container.py** ðŸ”—
    ConfiguraciÃ³n global e inyecciÃ³n de dependencias.
  - **file_io/** ðŸ“‚
    GestiÃ³n de lectura y escritura de archivos en distintos formatos (CSV, JSON, Parquet, YAML, HTML, PDF) y en diferentes orÃ­genes (local y AWS S3).
  - **db_connections/** ðŸ”Œ
    Conexiones a bases de datos (Postgres y MySQL) usando SQLAlchemy y patrones de repositorio/Unit of Work.
  - **extract/** ðŸ”
    Funcionalidades para la extracciÃ³n de datos (por ejemplo, desde el API TVMaze).
  - **transform/** ðŸ”„
    MÃ³dulo para transformar y normalizar la informaciÃ³n.
  - **load/** ðŸ“¤
    Carga de datos en la base de datos siguiendo patrones ETL.

- **tests/** âœ…
  Pruebas unitarias e integraciÃ³n que abarcan desde la gestiÃ³n de archivos hasta conexiones y operaciones con bases de datos y servicios de extracciÃ³n/carga.

Cada mÃ³dulo se apoya en principios de inyecciÃ³n de dependencias y patrones de diseÃ±o, asegurando un cÃ³digo desacoplado, testable y fÃ¡cil de extender.

## Patrones Aplicados

- **InyecciÃ³n de Dependencias** ðŸ”„
  Separa la creaciÃ³n y gestiÃ³n de objetos mediante contenedores, lo que facilita el desacoplamiento y la testabilidad del sistema.

- **Domain-Driven Design (DDD)** ðŸ›ï¸
  Enfoca la arquitectura en el dominio del negocio, creando un modelo claro que refleja la lÃ³gica y reglas empresariales.

- **Arquitectura Hexagonal** â›ï¸
  Organiza la aplicaciÃ³n en capas (nÃºcleo y adaptadores), permitiendo que la lÃ³gica central sea independiente de detalles tÃ©cnicos y de infraestructura.

- **Principios SOLID** ðŸ“
  Conjunto de prÃ¡cticas (SRP, OCP, LSP, ISP, DIP) que promueven un cÃ³digo modular, mantenible y flexible.

- **Patrones de DiseÃ±o** ðŸ”
  Soluciones reutilizables a problemas comunes que ayudan a estructurar y organizar el cÃ³digo de forma clara y escalable.

## Despliegue de la AplicaciÃ³n

Sigue estos pasos para desplegar la aplicaciÃ³n:

1. **Clonar el repositorio** ðŸ“¥
Clona el proyecto desde GitHub:
```bash
git clone https://github.com/julian-icruz/tech_test_lulo_bank
cd tu_repositorio
```

2. **Configurar variables de entorno** ðŸ”§
   Crea un archivo `.env` en la raÃ­z del proyecto y define las variables de entorno necesarias (por ejemplo, para Postgres, pgAdmin, etc.):

> Copiar tal y como esta para facilidad de ejecucion.

```env
############################
# AWS credentials and configuration
############################
AWS_ACCESS_KEY_ID="ASIA2"
AWS_SECRET_ACCESS_KEY="ZFBr5mto7J"
AWS_DEFAULT_REGION="us-east-1"
AWS_SESSION_TOKEN="IQo="

############################
# PGADMIN CONFIG
############################
PGADMIN_DEFAULT_EMAIL=admin@lulo.com
PGADMIN_DEFAULT_PASSWORD=Temporal123*
PGADMIN_SERVER_JSON_FILE=/servers.json

############################
# POSTGRES CONFIG
############################
POSTGRES_USER=lulo_bank_user
POSTGRES_PASSWORD=lulo_bank_password
POSTGRES_DB=lulo_bank_db
POSTGRES_PORT=5432
POSTGRES_HOST=postgres_lulo_bank
POSTGRES_LOCAL_DATA_PATH=/postgres_data
```

3. **Activar el entorno virtual con Poetry** ðŸ
   AsegÃºrate de tener instalado Poetry. Luego, instala las dependencias y activa el entorno:

> Asegurarse de tener una version de python correcta tal y como lo dice el .toml
```bash
poetry install
poetry .venv/bin/activate
```

4. **Ejecutar Docker Compose** ðŸ³
   Levanta los contenedores (Postgres, pgAdmin, migraciones y la aplicaciÃ³n) con:
```bash
docker-compose up --build
```

5. **Verificar el despliegue** ðŸ‘€
   - Abre tu navegador en [http://localhost:8080](http://localhost:8080) para ver la aplicaciÃ³n FastAPI en acciÃ³n.
   - Accede a [http://localhost](http://localhost) para abrir pgAdmin y administrar la base de datos.

   Las credenciales para acceder a la base de datos se enceuntrna en las vairables de entorno y serian estas:

```env

############################
# PGADMIN CONFIG / Para entrar al PGADMIN
############################
PGADMIN_DEFAULT_EMAIL=admin@lulo.com
PGADMIN_DEFAULT_PASSWORD=Temporal123*


############################
# POSTGRES CONFIG / Para entrar a la BD solo pedira la password
############################
POSTGRES_PASSWORD=lulo_bank_password

```
Â¡Listo! Con estos pasos tendrÃ¡s la aplicaciÃ³n corriendo y podrÃ¡s empezar a interactuar con ella.


## Resumen de Endpoints y CÃ³mo Usarlos

A continuaciÃ³n se describen los principales endpoints de la API junto con ejemplos de comandos `curl` para probar cada uno.

## Endpoints de Extract

### 1. Obtener Horario de TV
**Endpoint:**
`GET /v1/extract/schedule?date=YYYY-MM-DD`

**DescripciÃ³n:**
Este endpoint obtiene el horario de TV para la fecha especificada.

**Ejemplo:**
```bash
curl --location 'http://localhost:8080/v1/extract/schedule?date=2024-01-01'
```

### 2. Almacenar Horario de TV
**Endpoint:**
`POST /v1/extract/storage?date=YYYY-MM-DD`

**DescripciÃ³n:**
Extrae el horario de TV para la fecha indicada y almacena cada entrada en un archivo.
La configuraciÃ³n del escritor (source, file_format y engine) se envÃ­a en el cuerpo de la solicitud.

**Ejemplo:**
```bash
curl --location 'http://localhost:8080/v1/extract/storage?date=2024-01-01' \
--header 'Content-Type: application/json' \
--data '{
  "source": "local",
  "file_format": "json",
  "engine": "json"
}'
```

---


## Endpoints de Transform

### 3. Generar Reporte de Perfilado
**Endpoint:**
`POST /v1/transform/profiling`

**DescripciÃ³n:**
Procesa archivos de entrada para generar un reporte de perfilado en formato HTML.
El cuerpo de la solicitud debe incluir la configuraciÃ³n del lector, la configuraciÃ³n del escritor y la configuraciÃ³n de rutas de entrada y salida.

**Ejemplo:**
```bash
curl --location 'http://localhost:8080/v1/transform/profiling' \
--header 'Content-Type: application/json' \
--data '{
  "reader_config": {
    "source": "local",
    "file_format": "json",
    "engine": "pandas"
  },
  "writer_config": {
    "source": "local",
    "file_format": "html",
    "engine": "html"
  },
  "path_io": {
    "input_path": "json/date=2024-01-01/",
    "output_path": "profiling/date=2024-01-01/"
  }
}'
```

### 4. Limpieza de Datos
**Endpoint:**
`POST /v1/transform/cleaning`

**DescripciÃ³n:**
Lee archivos de datos crudos, los limpia y procesa, y escribe los datos procesados en el formato indicado (por ejemplo, Parquet).
El cuerpo de la solicitud debe incluir la configuraciÃ³n del lector, la configuraciÃ³n del escritor y las rutas de entrada y salida.

**Ejemplo:**
```bash
curl --location 'http://localhost:8080/v1/transform/cleaning' \
--header 'Content-Type: application/json' \
--data '{
  "reader_config": {
    "source": "local",
    "file_format": "json",
    "engine": "pandas"
  },
  "writer_config": {
    "source": "local",
    "file_format": "parquet",
    "engine": "pandas"
  },
  "path_io": {
    "input_path": "json/date=2024-01-01/",
    "output_path": "data/date=2024-01-01/"
  }
}'
```

---

## Endpoint de Load

### 5. Cargar Datos a la Base de Datos
**Endpoint:**
`POST /v1/load/to_db?database=postgres`

**DescripciÃ³n:**
Carga los datos procesados desde archivos en la base de datos especificada.
El cuerpo de la solicitud debe incluir la configuraciÃ³n del lector y la ruta de entrada de los archivos.

> Este solo se puede ejecutar una unica vez para cargar los datos luego tira error por lo que los datos yasse cargaron y se repetirian los IDs, si se quiere ejecutar nuevamete desde el PGADMIN se puede hacer

```sql
DELETE FROM <table_name>;
```

> recuerda la dependencia entre tablas para su eliminacion

**Ejemplo:**
```bash
curl --location 'http://localhost:8080/v1/load/to_db?database=postgres' \
--header 'Content-Type: application/json' \
--data '{
    "reader_config": {
        "source": "local",
        "file_format": "parquet",
        "engine": "pandas"
    },
    "path_io": {
        "input_path": "data/date=2024-01-01/"
    }
}'
```

---

Utiliza estos comandos para interactuar y probar los endpoints de la API. Ajusta las fechas y la configuraciÃ³n segÃºn sea necesario.

> Una vez se ejecutan los endpoints se generan los folders que se pedian en el challenge.

## Ejecutar Tests Unitarios

Para correr los tests unitarios, abre una terminal y ejecuta:

~~~bash
poetry run pytest
~~~
